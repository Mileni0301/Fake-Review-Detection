{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Topic Modelling\n",
    "\n",
    "In parallel with KMeans Clustering, we also would like to try clustering the review text using LDA Topic Modelling. The key difference between the 2 clustering methods is LDA topic modelling clusters reviews into different topics by solely looking at **text data** which in this case will be the review text. In contrast, KMeans Clustering can cluster the reviews based on **all features**, tokenized text and other numeric features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "ENGLISH_STOP_WORDS = stopwords.words('english')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bringing in just the reviewText from the dataset (require custom functions library)\n",
    "import functions_library as fl\n",
    "review_text = fl.cleanDF(fl.createPdDF('All_Beauty.json.gz'))['reviewText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                     great\n",
       "1         My  husband wanted to reading about the Negro ...\n",
       "2         This book was very informative, covering all a...\n",
       "3         I am already a baseball fan and knew a bit abo...\n",
       "4         This was a good story of the Black leagues. I ...\n",
       "                                ...                        \n",
       "362247    It was awful. It was super frizzy and I tried ...\n",
       "362248    I was skeptical about buying this.  Worried it...\n",
       "362249                             Makes me look good fast.\n",
       "362250    Way lighter than photo\\nNot mix blend of color...\n",
       "362251    No return instructions/phone # in packaging.  ...\n",
       "Name: reviewText, Length: 362252, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure it's loaded in properly\n",
    "review_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using same settings used for KMeans clustering to be consistent\n",
    "vectorizer = TfidfVectorizer(min_df = 1000, tokenizer = fl.spl_tokenizer, ngram_range = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tokens from reviewText\n",
    "word_matrix = vectorizer.fit_transform(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def print_topics(model, vectorizer, n_top_words):\n",
    "    words = vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\",\".join([words[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Topic Modelling with 25 Topics\n",
    "For LDA topic Modelling, we need to pre-select the number of topics we think exist in our text. To be consistent with KMeans clustering, I will choose 25 topics as we had selected 25 clusters for KMeans. Note: this is not necessarily the optimal way to determine the number of topics. Can make improvements in future iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting number of topics and also the top number of words we want to see from the model\n",
    "number_topics = 25\n",
    "number_words = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 10\n",
      "iteration: 2 of max_iter: 10\n",
      "iteration: 3 of max_iter: 10\n",
      "iteration: 4 of max_iter: 10\n",
      "iteration: 5 of max_iter: 10\n",
      "iteration: 6 of max_iter: 10\n",
      "iteration: 7 of max_iter: 10\n",
      "iteration: 8 of max_iter: 10\n",
      "iteration: 9 of max_iter: 10\n",
      "iteration: 10 of max_iter: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=25, n_jobs=4, verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit the LDA model\n",
    "lda = LDA(n_components=number_topics, n_jobs=4, verbose=1)\n",
    "lda.fit(word_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics found via LDA:\n",
      "\n",
      "Topic #0:\n",
      "good,deodorant,smell,smell good,natural,work,really good,taste,really,natural deodorant,tried,odor,far,like,day\n",
      "\n",
      "Topic #1:\n",
      "using,product,week,result,difference,day,skin,see,eye,use,ive,cream,used,month,every\n",
      "\n",
      "Topic #2:\n",
      "fast,amazing,thanks,shipping,delivery,fast shipping,quick,product,bad,super,shipped,wait,item,delivered,smell amazing\n",
      "\n",
      "Topic #3:\n",
      "great,work,work great,price,great price,good price,value,good,job,deal,look great,item,great job,look,buy\n",
      "\n",
      "Topic #4:\n",
      "nail,recommend,described,polish,highly,highly recommend,advertised,would recommend,would,product,anyone,recommend product,coat,recommend anyone,nail polish\n",
      "\n",
      "Topic #5:\n",
      "long,last,last long,long time,time,absolutely,little,love,absolutely love,way,go,lash,go long,long way,use\n",
      "\n",
      "Topic #6:\n",
      "teeth,water,floss,waterpik,gum,use,dentist,mouth,clean,flossing,one,dental,get,using,toothbrush\n",
      "\n",
      "Topic #7:\n",
      "love,stuff,fit,love stuff,perfectly,fine,wife,love smell,husband,comfortable,work fine,son,smell,work,everything\n",
      "\n",
      "Topic #8:\n",
      "year,thank,worked,old,store,find,amazon,product,one,year old,used,satisfied,worked great,ago,great\n",
      "\n",
      "Topic #9:\n",
      "color,perfect,lip,lipstick,love,like,love color,pink,dark,shade,look,really,light,brown,red\n",
      "\n",
      "Topic #10:\n",
      "money,happy,waste,waste money,star,purchase,high,5,dont,product,high quality,quality,fun,happy purchase,5 star\n",
      "\n",
      "Topic #11:\n",
      "skin,face,feel,product,dry,oil,use,love,cream,smell,make,lotion,like,sensitive,great\n",
      "\n",
      "Topic #12:\n",
      "hair,shampoo,product,soft,thick,brush,conditioner,curl,use,dry,love,make,curly,make hair,scalp\n",
      "\n",
      "Topic #13:\n",
      "work,hard,hair,dont,really,ear,cut,really work,comb,work good,get,good,use,know,find\n",
      "\n",
      "Topic #14:\n",
      "soap,scent,good product,good,smell,fragrance,product,bar,body,love,bath,lather,shower,wash,like\n",
      "\n",
      "Topic #15:\n",
      "nice,expected,exactly,brush,stand,wanted,look,made,smaller,arrived,needed,looking,sturdy,well made,size\n",
      "\n",
      "Topic #16:\n",
      "excellent,quality,work well,well,ok,work,product,love product,good quality,excellent product,good,love,great quality,service,product work\n",
      "\n",
      "Topic #17:\n",
      "easy,use,easy use,brush,small,bag,makeup,case,love,travel,great,kid,size,apply,perfect\n",
      "\n",
      "Topic #18:\n",
      "shaver,awesome,shave,norelco,one,battery,broke,razor,charge,trimmer,time,year,head,new,model\n",
      "\n",
      "Topic #19:\n",
      "great product,product,great,cute,worth,wonderful,product great,favorite,worth money,price,worth price,fantastic,money,well worth,gift\n",
      "\n",
      "Topic #20:\n",
      "like,smell,look,picture,wig,pretty,smell great,look like,okay,nothing,smell like,real,great,like picture,dont\n",
      "\n",
      "Topic #21:\n",
      "blade,razor,shave,shaving,sharp,didnt,didnt work,close,work,gillette,get,handle,working,good,smooth\n",
      "\n",
      "Topic #22:\n",
      "best,ever,beautiful,cheap,used,ive,ever used,clip,ive ever,piece,one,tape,foot,ive used,get\n",
      "\n",
      "Topic #23:\n",
      "received,product,broken,one,review,bottle,box,package,ring,would,return,came,like,disappointed,get\n",
      "\n",
      "Topic #24:\n",
      "loved,gift,love,daughter,buy,love love,bought,friend,christmas,compliment,would buy,liked,got,wife,would\n"
     ]
    }
   ],
   "source": [
    "# Print the topics found by the LDA model\n",
    "print(\"Topics found via LDA:\")\n",
    "print_topics(lda, vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, these are the top words for each topic. The results are pretty good: we can see topics related to specific types of products like topic 2 (shaving), topic 3 (teeth) and topic 17 (skin). Other topics are related to logistics such as topic 9 and 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lda_25.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving model to computer\n",
    "joblib.dump(lda,'lda_25.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this line if you need to load the model back into the notebook\n",
    "lda = joblib.load('lda_25.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
